# Data sub-setting and logical conditions

```{r package_options, include=FALSE}
knitr::opts_knit$set(global.par = TRUE)
```

```{r, include = FALSE}
par(bg = '#fdf6e3')
```

## Learning objectives

In this exercise, we will talk about sub-setting data sets, i.e. findings interesting observations and variables that we want to describe. Furthermore, we will introduce logical conditions in R. Logical conditions are often necessary for data wrangling.

### Sub-setting

When we deal with data sets and vectors such as data set's rows or columns, we want to be able to subset these objects. Sub-setting means, we access a specific part of the data set or vector. R comes with some small data sets included. The macroeconomic data set `longley` is one such data set. Lets have a look at what the data set contains by using the help files:

```{r eval=FALSE}
?longley
```

A data set is two-dimensional. It's first dimension are the rows. A 5 on the first dimension, therefore, means row 5. On the second dimension, we have columns. A 4 on the second dimension refers to column 4. We can identify each individual element in a data set by it's row and column coordinates. In R, we subset using square brackets `[ row.coordinates, column.coordinates ]`. In the square brackets, we place the row coordinates first, and column coordinates second. The coordinates are separated by a comma. If we want to see an entire row, we leave the column coordinate unspecified. The first row of the longley data set is:

```{r}
longley[ 1 , ]
```

The second column is:

```{r}
longley[ , 2 ]
```

The element in the first row and second column is:

```{r}
longley[ 1 , 2 ]
```

We can view a number of adjacent rows with the colon operator like so:

```{r}
longley[1 : 5 , ]
```

We can view a number of non adjacent rows using the vector function `c()` like so:

```{r}
longley[ c(1,3,5), ]
```

Furthermore, columns in data sets have names. These are the variable names. We can obtain a list of variable names with the `names()` function.

```{r}
names(longley)
```

This returns a vector of names. You may have noticed the quotation marks. Whenever you see quotation marks in R, you know this refers to a text. There are different storage or data types. Examples are numeric and character (text).

We can use the name of a variable for sub-setting a data set. Suppose, we want to see the population variable. We can either use 5 in square brackets because population is the 5th column or we can place the variable name within quotation marks in the brackets.

```{r}
longley[ , "Population"]
```

To access multiple variable columns by the variable names, we have to use the vector function `c()` like so:

```{r}
longley[ , c("GNP", "Armed.Forces", "Population") ]
```

Finally, we can also access a column in a data set using the dollar sign operator `$` like so:

```{r}
longley$Population
```

The population column is a vector. Vectors are 1-dimensional. We can subset vectors in the same way that we subset data sets except that we only need 1 coordinate to uniquely identify every element. Let's access the first element in the population column in three different but equivalent ways.

```{r}
# option 1s
longley$Population[1]

# option 2
longley[1 , 5]

# option 3
longley[1 , "Population"]
```

Finally, two useful sub-setting tricks:

1. the `-` operator means except and can be used to view all elements except the one specified
2. with the `length()` function we can find the last element of a vector

So, all rows in the longley data set except the first 5 would be:

```{r}
longley[ -1 : -5, ]
```

We can get the length of a vector using the `length()` function like so:

```{r}
length( longley[, 1] )
```


That is the length of the first column in the longley data set and because a data set is rectangular it gives us the number of rows in the data set as well. We get the last row in the longley data set like so: 

```{r}
longley[ length( longley[ , 1] ) , ]
```

To get the last element in the population vector of the longley data set, we would code:

```{r}
longley[ length(longley[,1]), "Population" ]
```

There are often many different approaches that will do the same thing. In does not matter how you get to a solution as long as get there. For instance, the `nrow()` function returns the number of rows in a data set or matrix object. So we could get the last element in the population vector using `nrow()` instead of `length()`:

```{r}
longley[ nrow(longley), "Population" ]
```

Sub-setting is essential for understanding data and manipulating it.

Finding the last column of the longley data set can be done using the `ncol()` function. The function returns the number of columns in the object that is supplied to the function. If we use that number in sub-setting, we can access the last column.


```{r class.source="collapsible"}
longley[ , ncol(longley) ]
```

### Logical conditions

We now load regional data from the European Union from the [Quality of Government Institute](http://qog.pol.gu.se/) to illustrate logical conditions and dealing with missing values. The data set is very large in the sense that it contains many different columns (variables)

<div class="container btn-container">
  <button type = "button" class = "btn btn-lg btn-success" onclick="window.open('./docs/qog_eureg_long_sep16.csv');">Download Data</button>
</div>

A full codebook of the data set is available online ([codebook](https://www.qogdata.pol.gu.se/data/qog_eureg_sep16.pdf)) 

We will use the following variables.

```{r echo = FALSE}
knitr::kable(tibble::tribble(
  ~Variable,     ~Description,
  "h_j",    "1 if Free Judiciary",
  "wdi_gdpc",      "Per capita wealth in US dollars",
  "undp_hdi",      "Human development index (higher values = higher quality of life)",
  "wbgi_cce",      "Control of corruption index (higher values = more control of corruption)",
  "wbgi_pse",    "Political stability index (higher values = more stable)",
  "former_col",    "1 = country was a colony once",
  "lp_lat_abst",    "Latitude of country's capital divided by 90"
))
```


```{r}
eu <- read.csv("qog_eureg_long_sep16.csv", stringsAsFactors = FALSE)
```

Before, we start working with the data set, do the following tasks on your own:

 1. check the dimensions of `eu`
 2. check the first 15 variable names of the data set 
 3. print the rows 120 to 130 of the data set and the following variables: "NUTS0", "region_name" and econ_2gdp_eur_hab (country name, region name, per capita wealth at current prices)
 
If you are unsure about a function that you need to complete this task, try looking for it online. For example, googling "R find names of a data set" will get you to the function that you need for solving this problem. R does have a steeper learning curve than more traditional data software like Excel. Therefore, it is good practice to get into the habit of searching and learning how to quickly find answers online.

<details>
<summary>Reveal content</summary>

The `dim()` function returns two numbers. The first is the number of rows and the second is the number of columns (if the object is two-dimensional). The function could also be used on arrays in which case it would also return the number of layers. We could have also found the number of rows using `nrow()` and the number of columns using `ncol()`. Or we could have used the `length()` function with sub-setting. For example, `length(eu[,1])` returns the length of the first column of the `u which is equal to the number of rows in the dataset. Equally, `length(eu[1,])` returns the length of the first row which is equal to the number of columns.

The `names()` function can be used on several objects such as data frames and lists. Here, `names()` returns the column names of the data set. In the case that you are dealing with a matrix instead of data frame &mdash; you can assess this by using `is.data.frame()` and `is.matrix()` &mdash; you would use the `colnames()` function for the column names. Here, we have so many variables that `names()` would fill our screen with a very long vector of variable names. Therefore, we subset the names vector to only display the first 5 variable names

We use `[]` for sub-setting. So `eu[1:6, 1:4]` returns the first six rows and the first four columns of the data set.

```{r}
# the dimensions: rows (observations) and columns (variables) 
dim(eu)

# the variable names
names(eu)[1:15]

# top 6 rows of the data
eu[120:130, c("NUTS0", "region_name", "econ_2gdp_eur_hab")]

eu$econ_2gdp_eur_hab
```
</details>

We now move to using logical conditions. Generally, R works with the following relational operators:

```{r echo = FALSE}
knitr::kable(tibble::tribble(
  ~Operator,     ~Effect,
  "==",    "Equal to",
  "!=",    "Not equal to",
  "<", "Less than",
  ">", "Greater than",
  "<=", "Less than or equal to",
  ">=", "Greater than or equal to"
))
```

In addition to these, we also have logical operators at our disposal, for example to chain relational operations together. Let's say we are interested in all nations where GDP is greater or equal to the first quartile and smaller or equal to the median. To do that we need the logical "AND" operator.

There are essentially two logical operators: (1) AND, (2) OR. We can perform these element-wise or only using the first observations. If we want to compare vectors, the and operator `&` compares all vector elements and the `&&` operator compares the first elements.


```{r echo = FALSE}
knitr::kable(tibble::tribble(
  ~Operator,     ~Effect,
  "!",    "Logical NOT",
  "&",    "Element-wise logical AND",
  "&&", "Logical AND",
  "|", "Element-wise logical OR",
  "||", "Logical OR",
))
```

To illustrate the difference between element-wise operations and evaluating the first element only, we create two vectors `x` and `y`.

```{r}
x <- c( TRUE, TRUE, FALSE, FALSE )
y <- c( FALSE, TRUE, FALSE, FALSE)

# element-wise AND
x & y

# first observations AND
x && y
```

We see that the difference is which elements of a vector are to be compared. Usually we use element wise comparison. Furthermore, we can use the functions `all()` and `any()` to evaluate whether all elements of a vector are the same or whether any element is different (we could use both `all()` and `any()` for this).

On your own, compare whether all elements are the same in `x` and `y`. 

<details>
<summary>Reveal content</summary>
```{r}
all( x == y)
```
The answer is that the vectors `x` and `y` differ in some elements. Let's find out where the differences lie.
</details>

Let's assume we want to know which elements of two vectors are equal. This is often necessary for merging data sets. Let's say we have two data sets and both contain the string "UK" as a country identifier for the United Kingdom. We now want to know which observations in both data sets refer to the UK. We can do this with relational operators and the `which()` function. Lets' get back to our mini-example. We want to compare which elements of `x` are different from the elements in `y`. Try to do this on your own.

```{r class.source="collapsible"}
which(x != y)
```

Notice that our code compares the first element of `x` with the first element of `y`, the second element of `x` with the second element of `y` and so on.

Let's apply our knowledge to the `eu` data set. You have the following tasks. 

  1. Check which countries our data set contains (hint: use either the `table()` function or the `unique()` function)
  1. Check which years  our data set contains (hint: use either the `table()` function or the `unique()` function on the variable `year`)
  2. Generate a data set called `uk` which contains only regions from the United Kingdom.
  3. Produce descriptive statistics for the wealth variable `econ_2gdp_eur_hab` (GPD per person by current prices)
  4. Display the observations that are above the median up until and including the third quartile in the year 2014 (only show the variables `region_name` and `econ_2gdp_eur_hab`).
  
<details>
<summary>Reveal content</summary>

```{r}
table(eu$NUTS0)0

uk <- eu[ eu$NUTS0 == "UK" , ]

summary(uk$econ_2gdp_eur_hab)

uk[ (uk$econ_2gdp_eur_hab > 26400 & uk$econ_2gdp_eur_hab <= 30350) & uk$year == 2014,  c("region_name", "econ_2gdp_eur_hab")]
```
  
The data set is quite messy. You can see that R displays a first column with strange content. These are row names and have no further significance for us. The row names carry over from the original `eu` data set. You can view the vector of row names by running the following R code:

```{r}
rownames(uk[ (uk$econ_2gdp_eur_hab > 26400 & uk$econ_2gdp_eur_hab <= 30350) & uk$year == 2014,  c("region_name", "econ_2gdp_eur_hab")])
```
  
</details>

### Re-naming variables

We want to rename `econ_2gdp_eur_hab` into something more meaningful. The new name should be *wealth*. We can use the `names()` function to get a vector of variable names like so: `names(eu)`.

We want to change the element of that vector which is `econ_2gdp_eur_hab` and we need the `which()` function to achieve this. Try to solve the problem on your own.


```{r class.source="collapsible"}
which( names(eu) ==  "econ_2gdp_eur_hab")
```

Great, now we know which column to look at. Now to rename the variable

```{r class.source="collapsible"}
names(eu)[ which( names(eu) ==  "econ_2gdp_eur_hab") ] <- "wealth"
```

We now check the variable names to confirm that we successfully changed the name.

```{r}
names(eu)[36]
```

#### Missing data

Let's have a look at the summary function on the `wealth` variable within the `eu` data set.

```{r}
summary(eu$wealth)
```

The `summary()` function informs us that there are 7896 missing values. We cannot calculate with missing values. For instance, `mean(eu$wealth)` will return `NA` unless we specifically instruct the `mean()` function to ignore missing values like so: `mean( eu$wealth, na.rm = TRUE )`. Some functions like `lm()` will just throw out missing values without informing us. Whenever we use `wealth` in calculation, we must remove missing values or fill in some estimates for the missing values.

Should we remove missing values from our data sets before carrying out analysis? The answer is, it depends. we should never remove missing values from variables that we are not interested in. The reason is that, we must keep the rectangular structure of data set intact. We therefore delete entire rows from our data set whenever we delete a missing value. If an observation is recorded for a variable we are interested in but missing for a variable that we are not interested in, then removing missings on the un-interesting variables would unnecessarily remove a recorded observation from a variable we are interested in.

However, removing missing values from a variable that we are interested in is fine. Remember though that statistical analyzes become less accurate (variance increases and bias may increase) through list-wise deletion. For statistics, imputing (estimating) missing values is often a better solution. We remove missing values from the `wealth` variable.

The function `is.na()` returns TRUE or FALSE for every element in the vector that we supply where TRUE means that the value is missing. We could reverse `is.na()` to mean is **not** NA like so: `!is.na()`. 

Try this on your own. But combine it with the `table()` function. So that instead of getting a very long vector of TRUE/FALSE we see the number of missings and non-missings.

```{r}
table(!is.na(eu$wealth))
```

We can subset our dataset to include only those observations that are not missing. Try this on your own:


```{r class.source="collapsible"}
eu <- eu[!is.na(eu$wealth), ]
```


We have now successfully removed missing values from the `wealth` variable which will make working with the variable a lot easier. We produce a few simple plots to describe our data which would require alot more code had we not removed missing values.


#### Simple plots

With the missing values removed from the `wealth` variable, we can now easily plot the distribution of that variable. The `density()` function will estimate the density of a variable which we can combine with the `plot()` function to give us an idea about the general distribution of that variable.

```{r}
plot(
  density(eu$wealth),
  bty = "n",
  main = "Distribution of Wealth in the EU"
)
```

Is this distribution right-skewed or positively skewed? Put differently, are there a few observations that are very wealthy but most are not? To illustrate let's add both the median and the mean to the plot. Recall that the mean is suseptible to outliers and hence in a right-skewed distribution the mean is greater than the median. 

```{r eval=FALSE}
lines(x = rep(mean(eu$wealth),10), y = seq(0, 4e-05, length.out = 10), col = "red", lwd = 2)
lines(x = rep(median(eu$wealth),10), y = seq(0, 4e-05, length.out = 10), col = "green", lwd = 2)
```


```{r include=FALSE}
plot(
  density(eu$wealth),
  bty = "n",
  main = "Distribution of Wealth in the EU"
)
lines(x = rep(mean(eu$wealth),10), y = seq(0, 4e-05, length.out = 10), col = "red", lwd = 2)
lines(x = rep(median(eu$wealth),10), y = seq(0, 4e-05, length.out = 10), col = "green", lwd = 2)
```

